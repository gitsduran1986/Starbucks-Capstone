{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17017 entries, 0 to 17188\n",
      "Data columns (total 23 columns):\n",
      "Unnamed: 0               17017 non-null int64\n",
      "offer_type               17017 non-null object\n",
      "offer_id                 17017 non-null object\n",
      "person                   17017 non-null object\n",
      "time                     17017 non-null int64\n",
      "difficulty               17017 non-null int64\n",
      "duration                 17017 non-null int64\n",
      "reward                   17017 non-null int64\n",
      "web                      17017 non-null int64\n",
      "email                    17017 non-null int64\n",
      "mobile                   17017 non-null int64\n",
      "social                   17017 non-null int64\n",
      "bogo                     17017 non-null int64\n",
      "discount                 17017 non-null int64\n",
      "informational            17017 non-null int64\n",
      "age                      17017 non-null int64\n",
      "income                   17017 non-null float64\n",
      "member_date_int          17017 non-null int64\n",
      "F                        17017 non-null int64\n",
      "M                        17017 non-null int64\n",
      "typical_spending_m1      17017 non-null float64\n",
      "num_offers               17017 non-null int64\n",
      "spending_during_offer    17017 non-null float64\n",
      "dtypes: float64(3), int64(17), object(3)\n",
      "memory usage: 3.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>reward</th>\n",
       "      <th>web</th>\n",
       "      <th>email</th>\n",
       "      <th>mobile</th>\n",
       "      <th>social</th>\n",
       "      <th>bogo</th>\n",
       "      <th>discount</th>\n",
       "      <th>informational</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>member_date_int</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>typical_spending_m1</th>\n",
       "      <th>num_offers</th>\n",
       "      <th>spending_during_offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.0</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "      <td>17017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38294.377211</td>\n",
       "      <td>334.227185</td>\n",
       "      <td>7.704413</td>\n",
       "      <td>6.772404</td>\n",
       "      <td>4.525181</td>\n",
       "      <td>0.794441</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971382</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.422871</td>\n",
       "      <td>0.464418</td>\n",
       "      <td>0.112711</td>\n",
       "      <td>64.182465</td>\n",
       "      <td>65770.022624</td>\n",
       "      <td>1303.206029</td>\n",
       "      <td>0.356232</td>\n",
       "      <td>0.481930</td>\n",
       "      <td>0.164729</td>\n",
       "      <td>2.067462</td>\n",
       "      <td>2.056270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21922.154990</td>\n",
       "      <td>195.430578</td>\n",
       "      <td>3.877208</td>\n",
       "      <td>2.060776</td>\n",
       "      <td>3.413907</td>\n",
       "      <td>0.404121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166736</td>\n",
       "      <td>0.405993</td>\n",
       "      <td>0.494030</td>\n",
       "      <td>0.498747</td>\n",
       "      <td>0.316248</td>\n",
       "      <td>27.261797</td>\n",
       "      <td>18510.039129</td>\n",
       "      <td>403.798460</td>\n",
       "      <td>0.478899</td>\n",
       "      <td>0.499688</td>\n",
       "      <td>0.189353</td>\n",
       "      <td>1.032515</td>\n",
       "      <td>5.721521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19256.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>54000.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037141</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38458.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>65405.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117070</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>57255.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>76000.000000</td>\n",
       "      <td>1609.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.232830</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>76271.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>1823.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.308020</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>31.670000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0          time    difficulty      duration        reward  \\\n",
       "count  17017.000000  17017.000000  17017.000000  17017.000000  17017.000000   \n",
       "mean   38294.377211    334.227185      7.704413      6.772404      4.525181   \n",
       "std    21922.154990    195.430578      3.877208      2.060776      3.413907   \n",
       "min        0.000000      0.000000      0.000000      3.000000      0.000000   \n",
       "25%    19256.000000    168.000000      5.000000      5.000000      2.000000   \n",
       "50%    38458.000000    408.000000     10.000000      7.000000      3.000000   \n",
       "75%    57255.000000    504.000000     10.000000      7.000000      5.000000   \n",
       "max    76271.000000    576.000000     20.000000     10.000000     10.000000   \n",
       "\n",
       "                web    email        mobile        social          bogo  \\\n",
       "count  17017.000000  17017.0  17017.000000  17017.000000  17017.000000   \n",
       "mean       0.794441      1.0      0.971382      0.791855      0.422871   \n",
       "std        0.404121      0.0      0.166736      0.405993      0.494030   \n",
       "min        0.000000      1.0      0.000000      0.000000      0.000000   \n",
       "25%        1.000000      1.0      1.000000      1.000000      0.000000   \n",
       "50%        1.000000      1.0      1.000000      1.000000      0.000000   \n",
       "75%        1.000000      1.0      1.000000      1.000000      1.000000   \n",
       "max        1.000000      1.0      1.000000      1.000000      1.000000   \n",
       "\n",
       "           discount  informational           age         income  \\\n",
       "count  17017.000000   17017.000000  17017.000000   17017.000000   \n",
       "mean       0.464418       0.112711     64.182465   65770.022624   \n",
       "std        0.498747       0.316248     27.261797   18510.039129   \n",
       "min        0.000000       0.000000     18.000000   30000.000000   \n",
       "25%        0.000000       0.000000     46.000000   54000.000000   \n",
       "50%        0.000000       0.000000     59.000000   65405.000000   \n",
       "75%        1.000000       0.000000     75.000000   76000.000000   \n",
       "max        1.000000       1.000000    118.000000  120000.000000   \n",
       "\n",
       "       member_date_int             F             M  typical_spending_m1  \\\n",
       "count     17017.000000  17017.000000  17017.000000         17017.000000   \n",
       "mean       1303.206029      0.356232      0.481930             0.164729   \n",
       "std         403.798460      0.478899      0.499688             0.189353   \n",
       "min           1.000000      0.000000      0.000000             0.000071   \n",
       "25%        1025.000000      0.000000      0.000000             0.037141   \n",
       "50%        1459.000000      0.000000      0.000000             0.117070   \n",
       "75%        1609.000000      1.000000      1.000000             0.232830   \n",
       "max        1823.000000      1.000000      1.000000             2.308020   \n",
       "\n",
       "         num_offers  spending_during_offer  \n",
       "count  17017.000000           17017.000000  \n",
       "mean       2.067462               2.056270  \n",
       "std        1.032515               5.721521  \n",
       "min        1.000000               0.000000  \n",
       "25%        1.000000               0.000000  \n",
       "50%        2.000000               0.000000  \n",
       "75%        3.000000               0.000000  \n",
       "max        6.000000              31.670000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "offers_recieved = pd.read_csv('for_model.csv')\n",
    "#offers_recieved = offers_recieved.drop(['id_x', 'id_y','value','person','offer_id','channels','influence_start',\n",
    "#                                       'influence_end','Unnamed: 0','event','offer_type','index'], axis=1)\n",
    "\n",
    "\n",
    "transcript = pd.read_json('data/transcript.json', orient='records', lines=True)\n",
    "portfolio = pd.read_json('data/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('data/profile.json', orient='records', lines=True)\n",
    "\n",
    "#remove top 1% of spending, model will focus too much on these\n",
    "offers_recieved = offers_recieved[offers_recieved['spending_during_offer'] < offers_recieved['spending_during_offer'].quantile(q=.99)]\n",
    "\n",
    "offers_recieved.info()\n",
    "offers_recieved.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training XGBoost Model and Finding the Best Parameter Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_for_model = offers_recieved.drop(['Unnamed: 0','offer_type'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = offers_for_model.iloc[:,:-1],offers_recieved.iloc[:,-1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,shuffle=True)\n",
    "\n",
    "X_train_for_model = X_train.drop(['person','offer_id'],axis=1)\n",
    "X_test_for_model = X_test.drop(['person','offer_id'],axis=1)\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X_train_for_model,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mini grid search over max depth and n_estimators to define the best parameter\n",
    "rmse = []\n",
    "for i in range(1,25,1):\n",
    "    for j in range(100,600,100):\n",
    "        xg = xgb.XGBRegressor(objective=\"reg:squarederror\",colsample_bytree = 0.3, learning_rate = .05,\n",
    "                    max_depth = i, n_estimators = j,alpha = 2)\n",
    "        xg.fit(X_train_for_model,y_train)\n",
    "        test_preds = xg.predict(X_test_for_model)\n",
    "        train_preds = xg.predict(X_train_for_model)\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "        rmse.append([i,j,train_rmse,test_rmse])\n",
    "    \n",
    "rmse = pd.DataFrame(rmse)\n",
    "rmse.to_csv('rmse.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rmse: 5.284352\n",
      "test rmse: 5.548542\n"
     ]
    }
   ],
   "source": [
    "#Using the best parameters, train a model and look at rmse outcomes for train and test\n",
    "xg = xgb.XGBRegressor(objective=\"reg:squarederror\",colsample_bytree = 0.3, learning_rate = .05,\n",
    "                    max_depth = 5, n_estimators = 100,alpha = 2)\n",
    "xg.fit(X_train_for_model,y_train)\n",
    "\n",
    "preds = xg.predict(X_train_for_model)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, preds))\n",
    "print(\"train rmse: %f\" % (train_rmse))\n",
    "\n",
    "test_preds = xg.predict(X_test_for_model)\n",
    "\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "print(\"test rmse: %f\" % (test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Model Actionable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duran\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#I want to make the model actionable by using it to identify which offer is \"optimal\" for each customer \n",
    "#ie, what offer does our model predict will lead to the highest spending by customer\n",
    "\n",
    "#first some simple data processing to get ready to make these predictions for each customer\n",
    "profile = X_test.groupby('person').mean()\n",
    "\n",
    "#same transformations used in data cleaning to get the same columns in portfolio of offers\n",
    "portfolio['web'] = pd.Series([0 for i in range(0,len(portfolio))])\n",
    "portfolio['email'] = pd.Series([0 for i in range(0,len(portfolio))])\n",
    "portfolio['mobile'] = pd.Series([0 for i in range(0,len(portfolio))])\n",
    "portfolio['social'] = pd.Series([0 for i in range(0,len(portfolio))])\n",
    "\n",
    "\n",
    "for index, i in enumerate(portfolio['channels']):\n",
    "    for j in i:\n",
    "        portfolio[j][index] = 1\n",
    "        \n",
    "portfolio = pd.concat([portfolio, pd.get_dummies(portfolio['offer_type'])], axis=1)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duran\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "def predict_portfolio(profile,portfolio,person,time):\n",
    "    '''For a given person and portolio of offers, predict spending during offer for each offer in the portfolio.  This helps\n",
    "    us a way to compare predictions for each type offer so we can decide which offer to provide. \n",
    "    inputs:\n",
    "    profile: the profile dataframe, essentially the test data with one row for each person for faster processing\n",
    "    portfolio: portfolio of offers with relevant data, formatted like train/test data\n",
    "    person: the id of the person of interest\n",
    "    time: time the offer will be made\n",
    "    returns: \n",
    "    dataframe of predicting variables then predicted spending outcomes for each type of offer, an optimal offer is\n",
    "    identified by highest predicted spending.   \n",
    "    '''\n",
    "    person_port = profile[profile.index == person]\n",
    "    person_port_ref = profile[profile.index == person]\n",
    "    for i in range(0,len(portfolio)):\n",
    "        person_port.loc[i,'time'] = time\n",
    "        person_port.loc[i,'difficulty'] = portfolio.loc[i,'difficulty']\n",
    "        person_port.loc[i,'duration'] = portfolio.loc[i,'duration']\n",
    "        person_port.loc[i,'reward'] = portfolio.loc[i,'reward']\n",
    "        person_port.loc[i,'web'] = portfolio.loc[i,'web']\n",
    "        person_port.loc[i,'email'] = portfolio.loc[i,'email']\n",
    "        person_port.loc[i,'mobile'] = portfolio.loc[i,'mobile']\n",
    "        person_port.loc[i,'social'] = portfolio.loc[i,'social']\n",
    "        person_port.loc[i,'bogo'] = portfolio.loc[i,'bogo']\n",
    "        person_port.loc[i,'discount'] = portfolio.loc[i,'discount']\n",
    "        person_port.loc[i,'informational'] = portfolio.loc[i,'informational']\n",
    "        person_port.loc[i,'age'] = person_port_ref.loc[person,'age']\n",
    "        person_port.loc[i,'income'] = person_port_ref.loc[person,'income']\n",
    "        person_port.loc[i,'member_date_int'] = person_port_ref.loc[person,'member_date_int']\n",
    "        person_port.loc[i,'M'] = person_port_ref.loc[person,'M']\n",
    "        person_port.loc[i,'F'] = person_port_ref.loc[person,'F']\n",
    "        person_port.loc[i,'typical_spending_m1'] = person_port_ref.loc[person,'typical_spending_m1']\n",
    "        person_port.loc[i,'num_offers'] = person_port_ref.loc[person,'num_offers']\n",
    "    person_port = person_port.iloc[1:]\n",
    "    preds = xg.predict(person_port)\n",
    "    person_port['person'] = person\n",
    "    person_port['portfolio_option'] = person_port.index\n",
    "    person_port.reset_index\n",
    "    person_port['preds'] = preds\n",
    "    person_port['offer_id'] = portfolio['id']\n",
    "    person_port['spending_bench'] = person_port['typical_spending_m1'] * person_port['duration'] \n",
    "    person_port['optimal'] = pd.Series([1 if i == max(preds) else 0 for i in preds])\n",
    "    final_df = person_port[['person','time','offer_id','portfolio_option','preds','optimal']]\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "#run this function for each person in the test set\n",
    "for i in range(0,len(profile.index)):\n",
    "    time = 0\n",
    "    person = profile.index[i]\n",
    "    if i == 0:\n",
    "        results_by_person = predict_portfolio(profile,portfolio,person,350)\n",
    "    else:\n",
    "        results_by_person = results_by_person.append(predict_portfolio(profile,portfolio,person,350))\n",
    "\n",
    "#send this csv to the marketing department! Use optimal offer to get customers to spend more\n",
    "results_by_person.to_csv('results_by_person_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ultimately Starbucks wants to make more money. Now that we know the optimal offer by person and time, can we draw some \n",
    "#conclusions about whether customers will spend more money if given such an offer?  Looking at offers in the test set, \n",
    "#I look at times the \"optimal\" offer was provided and when it was not.  We'd hope to see that customers tend to spend \n",
    "#more when they given the optimal offer.   \n",
    "\n",
    "test_set = pd.concat([X_test,y_test],axis=1)\n",
    "test_set = test_set.reset_index()\n",
    "\n",
    "optimal_offers = results_by_person[results_by_person['optimal'] == 1]\n",
    "\n",
    "opt_pred_list = []\n",
    "preds_index = optimal_offers.columns.get_loc('preds')\n",
    "for i in range(0,len(test_set)):\n",
    "    opt_pred = optimal_offers[optimal_offers['person'] == test_set.person[i]].iloc[0,preds_index]\n",
    "    opt_pred_list.append(opt_pred)\n",
    "\n",
    "opt_offerid_list = []\n",
    "offerid_index = optimal_offers.columns.get_loc('offer_id')\n",
    "for i in range(0,len(test_set)):\n",
    "    opt_offerid = optimal_offers[optimal_offers['person'] == test_set.person[i]].iloc[0,offerid_index]\n",
    "    opt_offerid_list.append(opt_offerid)\n",
    "    \n",
    "    \n",
    "test_set['opt_pred'] = pd.Series(opt_pred_list)\n",
    "opt_pred_index = test_set.columns.get_loc('opt_pred')\n",
    "test_set['pred'] = test_preds\n",
    "test_set['optimal_offer_id'] = pd.Series(opt_offerid_list)\n",
    "test_set['optimal'] = test_set['optimal_offer_id'] == test_set['offer_id']\n",
    "\n",
    "\n",
    "optimal_true = test_set[test_set['optimal'] == True]\n",
    "optimal_false = test_set[test_set['optimal'] == False]\n",
    "pct_diff = np.mean(optimal_true['spending_during_offer'])/np.mean(optimal_false['spending_during_offer'])-1\n",
    "\n",
    "offers_optimal = len(optimal_true)\n",
    "print('optimal offer given {}/{} times, {}%'.format(len(optimal_true),len(test_set),(len(optimal_true)/len(test_set))*100))\n",
    "print('avg spending when optimal offer given: {}'.format(np.mean(optimal_true['spending_during_offer'])))\n",
    "print('avg spending when optimal offer not given: {}'.format(np.mean(optimal_false['spending_during_offer'])))\n",
    "print('pct diff: ' + str(pct_diff*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Far from conclusive, but encouraging to see that spending is higher for those given what the model suggests could be the \"optimal\" offer.  Ultimate test is a more statistically rigourous test, but not bad to see.  Optimal offer is only provided ~10% of the time, likely because there are 10 offers probably being assigned randomly when data was created.  However, this suggests room for improvement and potential business value in using the model.  This approach does not take into account how much someone typically spends without an offer, there may be individuals who sending an offer to might decrease their spending. The following analysis attempts to account for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
