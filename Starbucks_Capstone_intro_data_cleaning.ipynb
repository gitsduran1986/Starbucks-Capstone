{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbucks Capstone Challenge\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This data set contains simulated data that mimics customer behavior on the Starbucks rewards mobile app. Once every few days, Starbucks sends out an offer to users of the mobile app. An offer can be merely an advertisement for a drink or an actual offer such as a discount or BOGO (buy one get one free). Some users might not receive any offer during certain weeks. \n",
    "\n",
    "Not all users receive the same offer, and that is the challenge to solve with this data set.\n",
    "\n",
    "Your task is to combine transaction, demographic and offer data to determine which demographic groups respond best to which offer type. This data set is a simplified version of the real Starbucks app because the underlying simulator only has one product whereas Starbucks actually sells dozens of products.\n",
    "\n",
    "Every offer has a validity period before the offer expires. As an example, a BOGO offer might be valid for only 5 days. You'll see in the data set that informational offers have a validity period even though these ads are merely providing information about a product; for example, if an informational offer has 7 days of validity, you can assume the customer is feeling the influence of the offer for 7 days after receiving the advertisement.\n",
    "\n",
    "You'll be given transactional data showing user purchases made on the app including the timestamp of purchase and the amount of money spent on a purchase. This transactional data also has a record for each offer that a user receives as well as a record for when a user actually views the offer. There are also records for when a user completes an offer. \n",
    "\n",
    "Keep in mind as well that someone using the app might make a purchase through the app without having received an offer or seen an offer.\n",
    "\n",
    "### Example\n",
    "\n",
    "To give an example, a user could receive a discount offer buy 10 dollars get 2 off on Monday. The offer is valid for 10 days from receipt. If the customer accumulates at least 10 dollars in purchases during the validity period, the customer completes the offer.\n",
    "\n",
    "However, there are a few things to watch out for in this data set. Customers do not opt into the offers that they receive; in other words, a user can receive an offer, never actually view the offer, and still complete the offer. For example, a user might receive the \"buy 10 dollars get 2 dollars off offer\", but the user never opens the offer during the 10 day validity period. The customer spends 15 dollars during those ten days. There will be an offer completion record in the data set; however, the customer was not influenced by the offer because the customer never viewed the offer.\n",
    "\n",
    "### Cleaning\n",
    "\n",
    "This makes data cleaning especially important and tricky.\n",
    "\n",
    "You'll also want to take into account that some demographic groups will make purchases even if they don't receive an offer. From a business perspective, if a customer is going to make a 10 dollar purchase without an offer anyway, you wouldn't want to send a buy 10 dollars get 2 dollars off offer. You'll want to try to assess what a certain demographic group will buy when not receiving any offers.\n",
    "\n",
    "### Final Advice\n",
    "\n",
    "Because this is a capstone project, you are free to analyze the data any way you see fit. For example, you could build a machine learning model that predicts how much someone will spend based on demographics and offer type. Or you could build a model that predicts whether or not someone will respond to an offer. Or, you don't need to build a machine learning model at all. You could develop a set of heuristics that determine what offer you should send to each customer (i.e., 75 percent of women customers who were 35 years old responded to offer A vs 40 percent from the same demographic to offer B, so send offer A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sets\n",
    "\n",
    "The data is contained in three files:\n",
    "\n",
    "* portfolio.json - containing offer ids and meta data about each offer (duration, type, etc.)\n",
    "* profile.json - demographic data for each customer\n",
    "* transcript.json - records for transactions, offers received, offers viewed, and offers completed\n",
    "\n",
    "Here is the schema and explanation of each variable in the files:\n",
    "\n",
    "**portfolio.json**\n",
    "* id (string) - offer id\n",
    "* offer_type (string) - type of offer ie BOGO, discount, informational\n",
    "* difficulty (int) - minimum required spend to complete an offer\n",
    "* reward (int) - reward given for completing an offer\n",
    "* duration (int) - time for offer to be open, in days\n",
    "* channels (list of strings)\n",
    "\n",
    "**profile.json**\n",
    "* age (int) - age of the customer \n",
    "* became_member_on (int) - date when customer created an app account\n",
    "* gender (str) - gender of the customer (note some entries contain 'O' for other rather than M or F)\n",
    "* id (str) - customer id\n",
    "* income (float) - customer's income\n",
    "\n",
    "**transcript.json**\n",
    "* event (str) - record description (ie transaction, offer received, offer viewed, etc.)\n",
    "* person (str) - customer id\n",
    "* time (int) - time in hours since start of test. The data begins at time t=0\n",
    "* value - (dict of strings) - either an offer id or transaction amount depending on the record\n",
    "\n",
    "**Note:** If you are using the workspace, you will need to go to the terminal and run the command `conda update pandas` before reading in the files. This is because the version of pandas in the workspace cannot read in the transcript.json file correctly, but the newest version of pandas can. You can access the termnal from the orange icon in the top left of this notebook.  \n",
    "\n",
    "You can see how to access the terminal and how the install works using the two images below.  First you need to access the terminal:\n",
    "\n",
    "<img src=\"pic1.png\"/>\n",
    "\n",
    "Then you will want to run the above command:\n",
    "\n",
    "<img src=\"pic2.png\"/>\n",
    "\n",
    "Finally, when you enter back into the notebook (use the jupyter icon again), you should be able to run the below cell without any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "\n",
    "# read in the json files\n",
    "portfolio = pd.read_json('data/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('data/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('data/transcript.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  event                            person  time  \\\n",
      "0        offer received  78afa995795e4d85b5d9ceeca43f5fef     0   \n",
      "1        offer received  a03223e636434f42ac4c3df47e8bac43     0   \n",
      "2        offer received  e2127556f4f64592b11af22de27a7932     0   \n",
      "3        offer received  8ec6ce2a7e7949b1bf142def7d0e0586     0   \n",
      "4        offer received  68617ca6246f4fbc85e91a2a49552598     0   \n",
      "5        offer received  389bc3fa690240e798340f5a15918d5c     0   \n",
      "6        offer received  c4863c7985cf408faee930f111475da3     0   \n",
      "7        offer received  2eeac8d8feae4a8cad5a6af0499a211d     0   \n",
      "8        offer received  aa4862eba776480b8bb9c68455b8c2e1     0   \n",
      "9        offer received  31dda685af34476cad5bc968bdb01c53     0   \n",
      "10       offer received  744d603ef08c4f33af5a61c8c7628d1c     0   \n",
      "11       offer received  3d02345581554e81b7b289ab5e288078     0   \n",
      "12       offer received  4b0da7e80e5945209a1fdddfe813dbe0     0   \n",
      "13       offer received  c27e0d6ab72c455a8bb66d980963de60     0   \n",
      "14       offer received  d53717f5400c4e84affdaeda9dd926b3     0   \n",
      "15       offer received  f806632c011441378d4646567f357a21     0   \n",
      "16       offer received  d058f73bf8674a26a95227db098147b1     0   \n",
      "17       offer received  65aba5c617294649aeb624da249e1ee5     0   \n",
      "18       offer received  ebe7ef46ea6f4963a7dd49f501b26779     0   \n",
      "19       offer received  1e9420836d554513ab90eba98552d0a9     0   \n",
      "20       offer received  868317b9be554cb18e50bc68484749a2     0   \n",
      "21       offer received  f082d80f0aac47a99173ba8ef8fc1909     0   \n",
      "22       offer received  102e9454054946fda62242d2e176fdce     0   \n",
      "23       offer received  4beeb3ed64dd4898b0edf2f6b67426d3     0   \n",
      "24       offer received  9f30b375d7bd4c62a884ffe7034e09ee     0   \n",
      "25       offer received  25c906289d154b66bf579693f89481c9     0   \n",
      "26       offer received  6e014185620b49bd98749f728747572f     0   \n",
      "27       offer received  02c083884c7d45b39cc68e1314fec56c     0   \n",
      "28       offer received  c0d210398dee4a0895b24444a5fcd1d2     0   \n",
      "29       offer received  8be4463721e14d7fa600686bf8c8b2ed     0   \n",
      "...                 ...                               ...   ...   \n",
      "306504      transaction  8524d450673b4c24869b6c94380006de   714   \n",
      "306505      transaction  b895c57e8cd047a8872ce02aa54759d6   714   \n",
      "306506  offer completed  b895c57e8cd047a8872ce02aa54759d6   714   \n",
      "306507     offer viewed  8dda575c2a1d44b9ac8e8b07b93d1f8e   714   \n",
      "306508      transaction  8431c16f8e1d440880db371a68f82dd0   714   \n",
      "306509  offer completed  8431c16f8e1d440880db371a68f82dd0   714   \n",
      "306510      transaction  ba620885e51c4b0ea64a4f61daad494f   714   \n",
      "306511      transaction  a1a8f40407c444cc848468275308958a   714   \n",
      "306512      transaction  8d80970192fa496f99d6b45c470a4b60   714   \n",
      "306513      transaction  bde275066f3c4fa0bff3093e3b866a2c   714   \n",
      "306514      transaction  f1e4fd36e5a0446f83861308bddf6945   714   \n",
      "306515      transaction  0b64be3b241c4407a5c9a71781173829   714   \n",
      "306516      transaction  86d03d35d7e0434b935e7743e83be3a0   714   \n",
      "306517      transaction  3408fd05c781401f8442fb6dbaaea9c7   714   \n",
      "306518      transaction  1593d617fac246ef8e50dbb0ffd77f5f   714   \n",
      "306519      transaction  f1b31d07b5d84f69a2d5f1d07843989e   714   \n",
      "306520      transaction  2ce987015ec0404a97ba333e8e814090   714   \n",
      "306521      transaction  2e33545f0a764d27b2ccff95fc8d72c4   714   \n",
      "306522      transaction  d1c4500ace2e45e9a45d3cd2fccac8d8   714   \n",
      "306523      transaction  b65affd9e07346a1906364a396950e3d   714   \n",
      "306524      transaction  d613ca9c59dd42f497bdbf6178da54a7   714   \n",
      "306525      transaction  eec70ab28af74a22a4aeb889c0317944   714   \n",
      "306526      transaction  24f56b5e1849462093931b164eb803b5   714   \n",
      "306527  offer completed  24f56b5e1849462093931b164eb803b5   714   \n",
      "306528      transaction  5ca2620962114246ab218fc648eb3934   714   \n",
      "306529      transaction  b3a1272bc9904337b331bf348c3e8c17   714   \n",
      "306530      transaction  68213b08d99a4ae1b0dcb72aebd9aa35   714   \n",
      "306531      transaction  a00058cf10334a308c68e7631c529907   714   \n",
      "306532      transaction  76ddbd6576844afe811f1a3c0fbb5bec   714   \n",
      "306533      transaction  c02b10e8752c4d8e9b73f918558531f7   714   \n",
      "\n",
      "                                                    value  \n",
      "0        {'offer id': '9b98b8c7a33c4b65b9aebfe6a799e6d9'}  \n",
      "1        {'offer id': '0b1e1539f2cc45b7b9fa7c272da2e1d7'}  \n",
      "2        {'offer id': '2906b810c7d4411798c6938adc9daaa5'}  \n",
      "3        {'offer id': 'fafdcd668e3743c1bb461111dcafc2a4'}  \n",
      "4        {'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}  \n",
      "5        {'offer id': 'f19421c1d4aa40978ebb69ca19b0e20d'}  \n",
      "6        {'offer id': '2298d6c36e964ae4a3e7e9706d1fb8c2'}  \n",
      "7        {'offer id': '3f207df678b143eea3cee63160fa8bed'}  \n",
      "8        {'offer id': '0b1e1539f2cc45b7b9fa7c272da2e1d7'}  \n",
      "9        {'offer id': '0b1e1539f2cc45b7b9fa7c272da2e1d7'}  \n",
      "10       {'offer id': '0b1e1539f2cc45b7b9fa7c272da2e1d7'}  \n",
      "11       {'offer id': '0b1e1539f2cc45b7b9fa7c272da2e1d7'}  \n",
      "12       {'offer id': 'ae264e3637204a6fb9bb56bc8210ddfd'}  \n",
      "13       {'offer id': '3f207df678b143eea3cee63160fa8bed'}  \n",
      "14       {'offer id': '0b1e1539f2cc45b7b9fa7c272da2e1d7'}  \n",
      "15       {'offer id': 'fafdcd668e3743c1bb461111dcafc2a4'}  \n",
      "16       {'offer id': '0b1e1539f2cc45b7b9fa7c272da2e1d7'}  \n",
      "17       {'offer id': '2906b810c7d4411798c6938adc9daaa5'}  \n",
      "18       {'offer id': '9b98b8c7a33c4b65b9aebfe6a799e6d9'}  \n",
      "19       {'offer id': 'ae264e3637204a6fb9bb56bc8210ddfd'}  \n",
      "20       {'offer id': '2906b810c7d4411798c6938adc9daaa5'}  \n",
      "21       {'offer id': '9b98b8c7a33c4b65b9aebfe6a799e6d9'}  \n",
      "22       {'offer id': '4d5c57ea9a6940dd891ad53e9dbe8da0'}  \n",
      "23       {'offer id': '2906b810c7d4411798c6938adc9daaa5'}  \n",
      "24       {'offer id': '2298d6c36e964ae4a3e7e9706d1fb8c2'}  \n",
      "25       {'offer id': '2906b810c7d4411798c6938adc9daaa5'}  \n",
      "26       {'offer id': 'f19421c1d4aa40978ebb69ca19b0e20d'}  \n",
      "27       {'offer id': 'ae264e3637204a6fb9bb56bc8210ddfd'}  \n",
      "28       {'offer id': '9b98b8c7a33c4b65b9aebfe6a799e6d9'}  \n",
      "29       {'offer id': 'fafdcd668e3743c1bb461111dcafc2a4'}  \n",
      "...                                                   ...  \n",
      "306504                                   {'amount': 4.89}  \n",
      "306505                                   {'amount': 4.48}  \n",
      "306506  {'offer_id': 'fafdcd668e3743c1bb461111dcafc2a4...  \n",
      "306507   {'offer id': '0b1e1539f2cc45b7b9fa7c272da2e1d7'}  \n",
      "306508                                   {'amount': 1.19}  \n",
      "306509  {'offer_id': 'fafdcd668e3743c1bb461111dcafc2a4...  \n",
      "306510                                  {'amount': 14.31}  \n",
      "306511                                   {'amount': 2.37}  \n",
      "306512                                   {'amount': 6.92}  \n",
      "306513                                  {'amount': 12.73}  \n",
      "306514                                    {'amount': 8.2}  \n",
      "306515                                    {'amount': 2.6}  \n",
      "306516                                    {'amount': 9.2}  \n",
      "306517                                   {'amount': 11.7}  \n",
      "306518                                  {'amount': 40.67}  \n",
      "306519                                  {'amount': 31.13}  \n",
      "306520                     {'amount': 1.6400000000000001}  \n",
      "306521                                  {'amount': 17.35}  \n",
      "306522                                   {'amount': 4.42}  \n",
      "306523                                  {'amount': 18.35}  \n",
      "306524                                  {'amount': 25.14}  \n",
      "306525                                  {'amount': 43.58}  \n",
      "306526                                  {'amount': 22.64}  \n",
      "306527  {'offer_id': 'fafdcd668e3743c1bb461111dcafc2a4...  \n",
      "306528                                    {'amount': 2.2}  \n",
      "306529                     {'amount': 1.5899999999999999}  \n",
      "306530                                   {'amount': 9.53}  \n",
      "306531                                   {'amount': 3.61}  \n",
      "306532                     {'amount': 3.5300000000000002}  \n",
      "306533                                   {'amount': 4.05}  \n",
      "\n",
      "[306534 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data Part I: Cleaning and combining portfolio and profile data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duran\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# a row of data for the ML model is going to be everything we know about an 'offer recieved': offer type, profile of offeree\n",
    "# $ spent by person within timespan of offer\n",
    "\n",
    "#first, break up offers from transactions\n",
    "offers = transcript[transcript['event'] != 'transaction'].reset_index()\n",
    "transactions = transcript[transcript['event'] == 'transaction'].reset_index()\n",
    "\n",
    "offer_val_index = offers.columns.get_loc('value')\n",
    "\n",
    "def get_offer(val_dict):\n",
    "    if 'offer id' in val_dict.keys():\n",
    "        return val_dict['offer id']\n",
    "    if 'offer_id' in val_dict.keys():\n",
    "        return val_dict['offer_id']\n",
    "\n",
    "#pull data out of the dictionary object\n",
    "offers['offer_id'] = pd.Series([get_offer(offers.iloc[i,offer_val_index]) for i in range(0,len(offers))])\n",
    "transactions['amount'] = pd.Series([float(transactions['value'].iloc[i].get('amount')) \n",
    "                                    for i in range(0,len(transactions['value']))])\n",
    "\n",
    "#clean up profile date, need to make the member since attribute and integer (days from min date)\n",
    "profile['member_date'] = pd.Series([pd.to_datetime(str(i)) for i in profile['became_member_on']])\n",
    "min_date = min(profile['member_date'])\n",
    "profile['member_date_int'] = pd.Series([i - min_date for i in profile['member_date']]).dt.days\n",
    "\n",
    "#make dummy variables for gender\n",
    "profile = pd.concat([profile, pd.get_dummies(profile['gender'])], axis=1)\n",
    "\n",
    "#impute values for income, add impute_income flag\n",
    "mean_income = round(np.mean(profile['income'][profile['income'].notnull()]))\n",
    "\n",
    "income, income_flag = [],[]\n",
    "for index, i in enumerate(profile['income'].isnull()):\n",
    "    if i:\n",
    "        income.append(mean_income)\n",
    "        income_flag.append(1)\n",
    "    else:\n",
    "        income.append(profile['income'][index])\n",
    "        income_flag.append(0)\n",
    "        \n",
    "profile['income'] = pd.Series(income)\n",
    "profile['income_impute_flag'] = pd.Series(income_flag)\n",
    "\n",
    "#remove redundant columns from profile dataframe\n",
    "profile_merge = profile.drop(['became_member_on','member_date','gender'],axis=1)\n",
    "\n",
    "#create new columns and extract binary variables for type of channel used\n",
    "portfolio['web'] = pd.Series([0 for i in range(0,len(portfolio))])\n",
    "portfolio['email'] = pd.Series([0 for i in range(0,len(portfolio))])\n",
    "portfolio['mobile'] = pd.Series([0 for i in range(0,len(portfolio))])\n",
    "portfolio['social'] = pd.Series([0 for i in range(0,len(portfolio))])\n",
    "\n",
    "for index, i in enumerate(portfolio['channels']):\n",
    "    for j in i:\n",
    "        portfolio[j][index] = 1\n",
    "        \n",
    "portfolio = pd.concat([portfolio, pd.get_dummies(portfolio['offer_type'])], axis=1)\n",
    "\n",
    "#merge cleaned up dataframes\n",
    "offers = offers.merge(portfolio,how='left',left_on='offer_id', right_on='id')\n",
    "offers = offers.merge(profile_merge,how='left',left_on='person', right_on='id')\n",
    "offers = offers.reset_index()\n",
    "\n",
    "\n",
    "offers_recieved = offers[offers['event'] == 'offer received']\n",
    "offers_recieved = offers_recieved.drop(['level_0'],axis=1).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data Part II: Quantifying the Outcomes of Offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for each offer recieved derive the start and end time of offer influence                                                                                                                                                                                                                                                                                                  \n",
    "offers_recieved['influence_start'] = offers_recieved['time']\n",
    "offers_recieved['influence_end'] = offers_recieved['time'] + offers_recieved['duration']\n",
    "\n",
    "def spending_in_window(offer_start,offer_end,person,transaction_df):\n",
    "    \"\"\"sums a customers spending during a window of an offer\n",
    "    Inputs:\n",
    "    offer start: when offer was sent\n",
    "    offer end: offer start + duration of offer\n",
    "    person: person offer was sent to\n",
    "    transaction_df: data frame of all transaction labeled offer completed.   \n",
    "    returns sum of spending within time window for a given customer.  \n",
    "    \"\"\"\n",
    "    sum_df = transaction_df[(transaction_df['time'] >= offer_start) & (transaction_df['time'] <= offer_end) \n",
    "                   & (transaction_df['person'] == person)]['amount'].values\n",
    "    if len(sum_df) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.sum(sum_df)\n",
    "    \n",
    "def check_viewed(offer_start,offer_end,person,offer_viewed_df):\n",
    "    \"\"\"searches transactions to see if they had an offer viewed event in the specified timespan\n",
    "    for an offer's influence.  \n",
    "    Inputs:\n",
    "    offer start: when offer was sent\n",
    "    offer end: offer start + duration of offer\n",
    "    person: person offer was sent to\n",
    "    offer_viewed_df: data frame of all transaction labeled offer_viewed.   \n",
    "    returns 1 if the offer has been viewed, 0 otherwise.  \n",
    "    \"\"\"\n",
    "    person_offer_df = offer_viewed_df[offer_viewed_df['person'] == person]\n",
    "    column_index = person_offer_df.columns.get_loc('time')\n",
    "    output = 0\n",
    "    if person_offer_df is None:\n",
    "        return output\n",
    "    else:\n",
    "        for i in range(0,len(person_offer_df)):\n",
    "            if person_offer_df.iloc[i,column_index] >= offer_start and person_offer_df.iloc[i,column_index] <= offer_end:\n",
    "                output = 1\n",
    "                break\n",
    "        return output\n",
    "\n",
    "\n",
    "#for each offer_recieved, check if it was viewed using function defined above.\n",
    "\n",
    "#add column with 1 if offer is viewed, or 0 if not\n",
    "offer_viewed = []\n",
    "for i in range(0,len(offers_recieved)):\n",
    "    offer_viewed.append(check_viewed(offers_recieved['influence_start'].iloc[i],\n",
    "                                        offers_recieved['influence_end'].iloc[i],\n",
    "                                        offers_recieved['person'].iloc[i],\n",
    "                                        offers[offers['event'] == 'offer viewed']))\n",
    "\n",
    "offers_recieved['offer_viewed'] = pd.Series(offer_viewed)\n",
    "\n",
    "#for each offer recieved, sum the spending that took place over the course of the offer\n",
    "\n",
    "spending_during_offer = []\n",
    "for i in range(0,len(offers_recieved)):\n",
    "    spending_during_offer.append(spending_in_window(offers_recieved['influence_start'].iloc[i],\n",
    "                                                    offers_recieved['influence_end'].iloc[i],\n",
    "                                                    offers_recieved['person'].iloc[i],\n",
    "                                                    transactions))\n",
    "    \n",
    "offers_recieved['spending_during_offer'] = pd.Series(spending_during_offer)\n",
    "\n",
    "#The above couple of calculations take a while to run, so save result in csv\n",
    "offers_recieved.to_csv(\"offers_recieved.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data Part III: Spending While Not Under \"Offer Influence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in csv from previous step, do some minor cleaning and create data frame to look at just offers that have been viewed\n",
    "offers_recieved = pd.read_csv('offers_recieved.csv')\n",
    "offers_recieved = offers_recieved.drop(['id_x', 'id_y','value','channels'], axis=1)\n",
    "offers_viewed = offers_recieved[offers_recieved['offer_viewed'] == 1]\n",
    "offers_viewed = offers_viewed.filter(['person','influence_start','influence_end','duration','spending_during_offer']).reset_index()\n",
    "\n",
    "\n",
    "def during_offer(person,offers_viewed_df,time):\n",
    "    \"\"\"flags a transaction if it took place while a person was under the influence of an offer\n",
    "    returns 1 if yes, it took place during an offer and 0 if not.  \n",
    "    inputs:\n",
    "    person: id of person from profile\n",
    "    offers_viewed: dataframe of offers recived, filtered by those that were viewed\n",
    "    time: timestamp for offer\n",
    "    \"\"\"\n",
    "    person_df = offers_viewed_df[offers_viewed_df['person'] == person]\n",
    "    offer_start_index = person_df.columns.get_loc('influence_start')\n",
    "    offer_end_index = person_df.columns.get_loc('influence_end')\n",
    "    output = 0\n",
    "    for i in range(0,len(person_df)):\n",
    "        if time >= person_df.iloc[i,offer_start_index] and time <= person_df.iloc[i,offer_end_index]:\n",
    "            output = 1\n",
    "            break\n",
    "    return output\n",
    "\n",
    "\n",
    "#for each transaction label it as having taken place while under the influence of an offer (offer recieved and viewed)\n",
    "person_index = transactions.columns.get_loc('person')\n",
    "time_index = transactions.columns.get_loc('time')\n",
    "during_offer_array = []\n",
    "for i in range(0,len(transactions)):\n",
    "    during_offer_array.append(during_offer(transactions.iloc[i,person_index],\n",
    "                                           offers_viewed,\n",
    "                                           transactions.iloc[i,time_index]))\n",
    "\n",
    "transactions['during_offer'] = pd.Series(during_offer_array)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data Part IV: Other Person Level Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep df to search over for person Level attributes, only looking at offers that have been viewed to speed up processsing\n",
    "offers_viewed = offers_recieved[offers_recieved['offer_viewed'] == 1]\n",
    "offers_viewed = offers_viewed.filter(['person','influence_start','influence_end','duration','spending_during_offer']).reset_index()\n",
    "\n",
    "def get_profile_transactions(person,transaction_df):\n",
    "    '''collects information from transactions df about each person in the profile\n",
    "    returns a list of attributes about persons transaction behavior:\n",
    "    [count of transactions, count of transaction not under the influence of any offer, sum of the ammount of transactions\n",
    "    time of first transaction, time of last transaction]\n",
    "    inputs:\n",
    "    person: person id from profile\n",
    "    transaction_df: transaction df to search\n",
    "    '''\n",
    "    person_df = transactions[transactions['person'] == person]\n",
    "    count = len(person_df)\n",
    "    count_nonoffer = len(person_df) - np.sum(person_df['during_offer'])\n",
    "    sum_t = np.sum(person_df[person_df['during_offer'] != 1]['amount'])\n",
    "    if len(person_df) == 0:\n",
    "        min_time = 0\n",
    "        max_time = 0\n",
    "    else:\n",
    "        min_time = min(person_df['time'])\n",
    "        max_time = max(person_df['time'])\n",
    "    return [count,count_nonoffer,sum_t,min_time,max_time]\n",
    "\n",
    "\n",
    "#for each person in profile df, use get_profile_transactions function to create attributes about people from transactions_df\n",
    "count, count_nonoffer, sum_amount, min_time, max_time = [],[],[],[],[]\n",
    "id_index = profile.columns.get_loc('id')\n",
    "for i in range(0,len(profile)):\n",
    "    l = get_profile_transactions(profile.iloc[i,id_index],transactions)\n",
    "    count.append(l[0])\n",
    "    count_nonoffer.append(l[1])\n",
    "    sum_amount.append(l[2])\n",
    "    min_time.append(l[3])\n",
    "    max_time.append(l[4])\n",
    "\n",
    "#store attributes in profile df\n",
    "profile['nonoffer_trans_count'] = pd.Series(count_nonoffer)  \n",
    "profile['sum_nonoffer_trans'] = pd.Series(sum_amount)  \n",
    "profile['trans_count'] = pd.Series(count)  \n",
    "profile['first_trans'] = pd.Series(min_time)  \n",
    "profile['last_trans'] = pd.Series(max_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_profile_offers(person,offers_df):\n",
    "    '''collects information from offers viewed about each person in the profile\n",
    "    returns a list of attraibutes about offers a person has recieved as well as their spending:\n",
    "    [count of offers,sum of the total days the person has been under influence of offer, sum of spending during offers]\n",
    "    inputs:\n",
    "    person: person id from profile\n",
    "    offer_df: offer viewed df to search\n",
    "    '''\n",
    "    person_df = offers_df[offers_df['person'] == person]\n",
    "    num_offers = len(person_df)\n",
    "    tot_offer_duration = np.sum(person_df['duration'])\n",
    "    tot_offer_spending = np.sum(person_df['spending_during_offer'])\n",
    "    return [num_offers,tot_offer_duration,tot_offer_spending]\n",
    "\n",
    "#collect information about people from offers_viwed df, num offers, sum of offer duration and their total spending during offers\n",
    "num_offers, tot_offer_duration, tot_offer_spending,  = [],[],[]\n",
    "id_index = profile.columns.get_loc('id')\n",
    "for i in range(0,len(profile)):\n",
    "    l = get_profile_offers(profile.iloc[i,id_index],offers_viewed)\n",
    "    num_offers.append(l[0])\n",
    "    tot_offer_duration.append(l[1])\n",
    "    tot_offer_spending.append(l[2])\n",
    "\n",
    "#store these attributes in profiles df\n",
    "profile['num_offers'] = pd.Series(num_offers)  \n",
    "profile['tot_offer_duration'] = pd.Series(tot_offer_duration)  \n",
    "profile['tot_offer_spending'] = pd.Series(tot_offer_spending)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to run some calculations withing profile df to finalize these attributes before merging them with offers recieved\n",
    "\n",
    "max_length = max(transactions['time'])\n",
    "#method 1 to define typical spending.  spending w/o offer / (maxtime - duration offers)\n",
    "profile['typical_spending_m1'] = profile['sum_nonoffer_trans']/(max_length - profile['tot_offer_duration'])\n",
    "#method 2 to define typical spending.  spending w/o offer / (diff between max/min tranction time - duration offers)\n",
    "profile['typical_spending_m2'] = profile['sum_nonoffer_trans']/(profile['last_trans'] - profile['first_trans']  - profile['tot_offer_duration'])\n",
    "#another attribute is how much a person typically spends under offer influence\n",
    "profile['avg_offer_spending'] = profile['tot_offer_spending']/profile['tot_offer_duration']\n",
    "\n",
    "#remove some unwanted columns, chose to move forward with typical spending m2\n",
    "profile_merge = profile.filter(['id','num_offers','typical_spending_m1']).reset_index()\n",
    "\n",
    "#finally merge profile with offers recieved transactions\n",
    "offers_recieved = offers_recieved.merge(profile_merge,how='left',left_on='person', right_on='id')\n",
    "\n",
    "#again save the csv as a check point\n",
    "offers_recieved.to_csv('offers_recieved.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalize Data to Send to Modeling Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17671 entries, 0 to 76271\n",
      "Data columns (total 22 columns):\n",
      "offer_type               17671 non-null object\n",
      "offer_id                 17671 non-null object\n",
      "person                   17671 non-null object\n",
      "time                     17671 non-null int64\n",
      "difficulty               17671 non-null int64\n",
      "duration                 17671 non-null int64\n",
      "reward                   17671 non-null int64\n",
      "web                      17671 non-null int64\n",
      "email                    17671 non-null int64\n",
      "mobile                   17671 non-null int64\n",
      "social                   17671 non-null int64\n",
      "bogo                     17671 non-null int64\n",
      "discount                 17671 non-null int64\n",
      "informational            17671 non-null int64\n",
      "age                      17671 non-null int64\n",
      "income                   17671 non-null float64\n",
      "member_date_int          17671 non-null int64\n",
      "F                        17671 non-null int64\n",
      "M                        17671 non-null int64\n",
      "typical_spending_m1      17671 non-null float64\n",
      "num_offers               17671 non-null int64\n",
      "spending_during_offer    17671 non-null float64\n",
      "dtypes: float64(3), int64(16), object(3)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#read in csv from previous steps\n",
    "offers_recieved = pd.read_csv('offers_recieved.csv')\n",
    "\n",
    "#we only care about the influence of the model when it has been viewed, remove offers that have not be viewed\n",
    "offers_recieved = offers_recieved[offers_recieved['offer_viewed'] == 1]\n",
    "\n",
    "columns_to_use = ['offer_type','offer_id','person','time','difficulty','duration','reward','web','email','mobile','social','bogo','discount','informational',\n",
    "                 'age','income','member_date_int','F','M','income_inpute_flag','typical_spending_m1','num_offers','spending_during_offer']\n",
    "\n",
    "#filter columns, take one last look at info and send to csv for modeling steps\n",
    "offers_recieved = offers_recieved.filter(columns_to_use)\n",
    "\n",
    "offers_recieved.info()\n",
    "\n",
    "offers_recieved.to_csv('for_model.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
